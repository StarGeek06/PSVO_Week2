{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5004740,"sourceType":"datasetVersion","datasetId":2903798},{"sourceId":9659518,"sourceType":"datasetVersion","datasetId":5901326}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:31.468092Z\",\"iopub.execute_input\":\"2024-10-18T15:31:31.468735Z\",\"iopub.status.idle\":\"2024-10-18T15:31:31.483427Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:31.468597Z\",\"shell.execute_reply\":\"2024-10-18T15:31:31.482137Z\"}}\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers, Model\nimport cv2\nimport os\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:31.486622Z\",\"iopub.execute_input\":\"2024-10-18T15:31:31.487157Z\",\"iopub.status.idle\":\"2024-10-18T15:31:38.331694Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:31.487105Z\",\"shell.execute_reply\":\"2024-10-18T15:31:38.330299Z\"}}\ninput_dir = '/kaggle/input/deepfashion-1/datasets'\nimages_dir = os.path.join(input_dir, 'train_images')\nmasks_dir = os.path.join(input_dir, 'segm')\n\nfor dirname, _, filenames in os.walk(images_dir):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:38.333842Z\",\"iopub.execute_input\":\"2024-10-18T15:31:38.334262Z\",\"iopub.status.idle\":\"2024-10-18T15:31:46.486610Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:38.334206Z\",\"shell.execute_reply\":\"2024-10-18T15:31:46.485436Z\"}}\nimport matplotlib.pyplot as plt\n\n# Fonction pour charger les images et masques en petits lots\ndef load_images_in_batches(images_dir, masks_dir, batch_size=32):\n    image_files = sorted(os.listdir(images_dir))\n    mask_files = sorted(os.listdir(masks_dir))\n    \n    for i in range(0, len(image_files), batch_size):\n        batch_images = [cv2.imread(os.path.join(images_dir, img)) for img in image_files[i:i+batch_size]]\n        batch_masks = [cv2.imread(os.path.join(masks_dir, mask), 0) for mask in mask_files[i:i+batch_size]]\n        \n        return batch_images , batch_masks\n\n# Appel de la fonction pour charger les images et masques en petits lots\nbatch_images, batch_masks = load_images_in_batches(images_dir, masks_dir, batch_size=32)\n\n\ndef display_samples(images, masks, num=15):\n    for i in range(num):\n        fig, ax = plt.subplots(1, 2)\n        ax[0].imshow(images[i])\n        ax[1].imshow(masks[i], cmap='gray')\n        plt.show()\n\ndisplay_samples(batch_images, batch_masks)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:46.489019Z\",\"iopub.execute_input\":\"2024-10-18T15:31:46.489440Z\",\"iopub.status.idle\":\"2024-10-18T15:31:46.534980Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:46.489397Z\",\"shell.execute_reply\":\"2024-10-18T15:31:46.533290Z\"}}\n\n# Convertir en tableaux numpy\ntrain_images = np.array(batch_images)\ntrain_masks = np.array(batch_masks)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:46.536562Z\",\"iopub.execute_input\":\"2024-10-18T15:31:46.536955Z\",\"iopub.status.idle\":\"2024-10-18T15:31:46.643596Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:46.536916Z\",\"shell.execute_reply\":\"2024-10-18T15:31:46.642454Z\"}}\n\n# Diviser les données : 80 % pour l'entraînement, 20 % pour la validation\ntrain_images, val_images, train_masks, val_masks = train_test_split(train_images, train_masks, test_size=0.2, random_state=42)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:46.644950Z\",\"iopub.execute_input\":\"2024-10-18T15:31:46.645305Z\",\"iopub.status.idle\":\"2024-10-18T15:31:46.686267Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:46.645261Z\",\"shell.execute_reply\":\"2024-10-18T15:31:46.685162Z\"}}\n\n# Redimensionner les images et masques\nIMG_HEIGHT, IMG_WIDTH = 256, 256\ntrain_images = np.array([cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT)) for img in train_images])\ntrain_masks = np.array([cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT)) for mask in train_masks])\nval_images = np.array([cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT)) for img in val_images])\nval_masks = np.array([cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT)) for mask in val_masks])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:46.688080Z\",\"iopub.execute_input\":\"2024-10-18T15:31:46.688534Z\",\"iopub.status.idle\":\"2024-10-18T15:31:46.736960Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:46.688495Z\",\"shell.execute_reply\":\"2024-10-18T15:31:46.735578Z\"}}\n# Normalisation des pixels\ntrain_images = train_images / 255.0\nval_images = val_images / 255.0\ntrain_masks = train_masks / 255.0\nval_masks = val_masks / 255.0\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:46.738348Z\",\"iopub.execute_input\":\"2024-10-18T15:31:46.738696Z\",\"iopub.status.idle\":\"2024-10-18T15:31:46.744677Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:46.738662Z\",\"shell.execute_reply\":\"2024-10-18T15:31:46.743330Z\"}}\n\n# Reshape des masques\ntrain_masks = np.expand_dims(train_masks, axis=-1)\nval_masks = np.expand_dims(val_masks, axis=-1)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:46.746597Z\",\"iopub.execute_input\":\"2024-10-18T15:31:46.746956Z\",\"iopub.status.idle\":\"2024-10-18T15:31:46.767555Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:46.746915Z\",\"shell.execute_reply\":\"2024-10-18T15:31:46.766322Z\"}}\n\n# Modèle U-Net\ndef unet_model(input_size=(256, 256, 3)):\n    \n    ## ------ Chemin Contractant -------- ##\n    inputs = layers.Input(input_size)\n    # Bloc1\n    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n    # Bloc2\n    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    # Bloc 3\n    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    # Bloc 4\n    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    # Bloc 5\n    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n\n    ## -- Chemin Expansif ----- #\n    # Bloc 6\n    up6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n    up6 = layers.concatenate([up6, conv4])\n    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n\n    # Bloc 7\n    up7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n    up7 = layers.concatenate([up7, conv3])\n    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n\n    # Bloc 8\n    up8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n    up8 = layers.concatenate([up8, conv2])\n    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n\n    # Bloc 9\n    up9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n    up9 = layers.concatenate([up9, conv1])\n    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n\n    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    model = Model(inputs, outputs)\n    return model\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:46.771218Z\",\"iopub.execute_input\":\"2024-10-18T15:31:46.771719Z\",\"iopub.status.idle\":\"2024-10-18T15:31:47.264127Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:46.771677Z\",\"shell.execute_reply\":\"2024-10-18T15:31:47.262803Z\"}}\nmodel = unet_model()\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T15:31:47.265801Z\",\"iopub.execute_input\":\"2024-10-18T15:31:47.266184Z\",\"iopub.status.idle\":\"2024-10-18T15:45:07.761939Z\",\"shell.execute_reply.started\":\"2024-10-18T15:31:47.266145Z\",\"shell.execute_reply\":\"2024-10-18T15:45:07.759902Z\"}}\n\n# Entraînement du modèle\nmodel.fit(train_images, train_masks, validation_data=(val_images, val_masks), epochs=10\n          , batch_size=32)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T16:03:25.337402Z\",\"iopub.execute_input\":\"2024-10-18T16:03:25.338108Z\",\"iopub.status.idle\":\"2024-10-18T16:03:25.344476Z\",\"shell.execute_reply.started\":\"2024-10-18T16:03:25.338049Z\",\"shell.execute_reply\":\"2024-10-18T16:03:25.342980Z\"}}\nimage_path = '/kaggle/input/data-th/WhatsApp Image 2024-10-16 at 11.29.33.jpeg'  \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T16:03:28.830668Z\",\"iopub.execute_input\":\"2024-10-18T16:03:28.831154Z\",\"iopub.status.idle\":\"2024-10-18T16:03:29.308250Z\",\"shell.execute_reply.started\":\"2024-10-18T16:03:28.831113Z\",\"shell.execute_reply\":\"2024-10-18T16:03:29.306807Z\"}}\n# 1. Charger l'Image\nimage = cv2.imread(image_path)\n\n# 2. Redimensionner l'Image\nimage_resized = cv2.resize(image, (256, 256))\n\n# 3. Normaliser les Pixels\nimage_normalized = image_resized / 255.0\n\n# 4. Reshape l'Image\nimage_input = np.expand_dims(image_normalized, axis=0)  # Ajout d'une dimension pour faire (1, 256, 256, 3)\n\n# Vérification de la forme de l'image après prétraitement\nprint(\"Forme de l'image d'entrée :\", image_input.shape)\n\n# Afficher l'image originale et l'image prétraitée\nplt.figure(figsize=(10, 5))\n\n# Image originale\nplt.subplot(1, 2, 1)\nplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\nplt.title('Image Originale')\nplt.axis('off')\n\n# Image prétraitée\nplt.subplot(1, 2, 2)\nplt.imshow(image_normalized)\nplt.title('Image Prétraitée')\nplt.axis('off')\n\nplt.show()\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T16:06:04.179075Z\",\"iopub.execute_input\":\"2024-10-18T16:06:04.179539Z\",\"iopub.status.idle\":\"2024-10-18T16:06:05.286338Z\",\"shell.execute_reply.started\":\"2024-10-18T16:06:04.179496Z\",\"shell.execute_reply\":\"2024-10-18T16:06:05.284968Z\"}}\n# Prédire le masque avec le modèle U-Net\npredicted_mask = model.predict(image_input)\n\n# Afficher le masque prédit\nplt.figure(figsize=(5, 5))\nplt.imshow(predicted_mask[0, :, :, 0])  # Afficher le masque prédit\nplt.title('Masque Prédit')\nplt.axis('off')\nplt.show()\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T16:40:24.453681Z\",\"iopub.execute_input\":\"2024-10-18T16:40:24.454680Z\",\"iopub.status.idle\":\"2024-10-18T16:40:41.877633Z\",\"shell.execute_reply.started\":\"2024-10-18T16:40:24.454632Z\",\"shell.execute_reply\":\"2024-10-18T16:40:41.875875Z\"}}\npip install gradio\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-10-18T16:42:53.311879Z\",\"iopub.execute_input\":\"2024-10-18T16:42:53.312652Z\",\"iopub.status.idle\":\"2024-10-18T16:42:56.378841Z\",\"shell.execute_reply.started\":\"2024-10-18T16:42:53.312608Z\",\"shell.execute_reply\":\"2024-10-18T16:42:56.377839Z\"}}\nimport gradio as gr\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.models import load_model\n\n\n# Pré-traitement de l'image : redimensionnement et normalisation\ndef preprocess_image(image):\n    try:\n        image_resized = cv2.resize(image, (256, 256))\n        image_normalized = image_resized / 255.0  # Normaliser entre 0 et 1\n        image_input = np.expand_dims(image_normalized, axis=0)  # Ajouter la dimension batch\n        return image_input\n    except Exception as e:\n        print(f\"Erreur dans le pré-traitement de l'image : {str(e)}\")\n        return None\n\n# Post-traitement du masque pour affichage\ndef postprocess_mask(mask, original_image_shape):\n    try:\n        mask_resized = cv2.resize(mask, (original_image_shape[1], original_image_shape[0]))  # Redimensionner\n        return mask_resized\n    except Exception as e:\n        print(f\"Erreur dans le post-traitement du masque : {str(e)}\")\n        return None\n\n# Fonction de prédiction\ndef predict_mask(image):\n    try:\n        # Prétraiter l'image\n        image_input = preprocess_image(image)\n        if image_input is None:\n            return \"Erreur lors du prétraitement de l'image\", None\n        \n        # Faire la prédiction\n        predicted_mask = model.predict(image_input)[0]  # Prédiction, on retire le batch\n        if predicted_mask is None:\n            return \"Erreur lors de la prédiction\", None\n        \n        # Post-traitement du masque pour affichage\n        predicted_mask_resized = postprocess_mask(predicted_mask, image.shape)\n        if predicted_mask_resized is None:\n            return \"Erreur lors du post-traitement du masque\", None\n        \n        # Retourner l'image d'origine et le masque prédit\n        return image, predicted_mask_resized\n    except Exception as e:\n        print(f\"Erreur dans la fonction de prédiction : {str(e)}\")\n        return f\"Erreur : {str(e)}\", None\n\n# Interface Gradio\ninterface = gr.Interface(\n    fn=predict_mask,\n    inputs=gr.Image(type=\"numpy\"),  # L'image sera chargée sous forme de tableau numpy\n    outputs=[gr.Image(type=\"numpy\", label=\"Image Originale\"), \n             gr.Image(type=\"numpy\", label=\"Masque Prédit\")],\n    title=\"U-Net Segmentation de Vêtements\",\n    description=\"Téléchargez une image et le modèle U-Net prédira le masque de segmentation.\"\n)\n\n# Lancer l'interface\ninterface.launch(share=True)  # Utilisez share=True si vous êtes dans un environnement distant (Kaggle, Colab)\n\n\n# %% [code]\n","metadata":{"_uuid":"4777388c-454f-4f51-be57-cea3648c9019","_cell_guid":"343fc709-1ad5-4388-9fcb-f53026eff480","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}